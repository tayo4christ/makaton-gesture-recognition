# ğŸ—ºï¸ Makaton Gesture Recognition â€” Roadmap

This document outlines planned milestones for the Makaton Gesture Recognition System,
a computer visionâ€“based AI tool for translating Makaton gestures into English text.

---

## âœ… Current Progress
- Prototype GUI built using Python, OpenCV, and MediaPipe.
- Basic static gesture recognition functional (Hello, Goodbye, Please, Thank You, Yes).
- Integrated early feedback from Derby Cathedral School testing.
- Pre-commit hooks, linting, and CI setup on GitHub Actions.
- Intellectual Property filing submitted to the UK Intellectual Property Office (awaiting payment).

---

## ğŸ§  Next Development Milestones

### ğŸ”¹ Phase 1: Dataset & Model
- Collect extended Makaton gesture dataset.
- Label samples for 20â€“30 common gestures.
- Train CNN-based classifier for dynamic gestures.

### ğŸ”¹ Phase 2: Translation Layer
- Map recognized gestures to full English phrases.
- Integrate optional speech synthesis (Text-to-Speech).

### ğŸ”¹ Phase 3: Accessibility Features
- Add larger buttons and captions for low-vision users.
- Integrate keyboard shortcuts for educators.

### ğŸ”¹ Phase 4: Web Deployment
- Deploy live demo using Streamlit or Gradio.
- Enable webcam access directly in browser.

---

## ğŸ“… Long-Term Vision
Develop a multilingual Makaton-to-English translation suite that supports gesture, symbol, and speech integration.
Potential collaborations: NHS communication support units, SEND schools, and inclusive education technology hubs.

---

## ğŸ‘©â€ğŸ’» Maintainer
**Omotayo Omoyemi**
MSc in Computer Science | AI & Education Researcher
